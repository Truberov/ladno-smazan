# ladno-smazan

![kandinsky-download-1727581197737](assets/123.png)

 # :robot: AI Assistant for Advertising Agency Data Search 

### Команда AiRina представляет решение по разработке интеллектуального помощника для рекламных агентств


## :building_construction: ## Описание проекта

Этот проект представляет собой готовое решение для рекламных агентств, позволяющее эффективно искать информацию в больших массивах данных, что ускоряет процесс принятия решений и разработки стратегий. Разработанный чат-бот с веб-интерфейсом предоставляет удобные инструменты для быстрого поиска релевантной информации в библиотеке материалов агентства, которая включает текстовую и презентационную информацию.

Чат-бот оперативно находит нужные данные и предоставляет ссылки на искомую информацию, а также позволяет пользователям легко дополнять базу данных новыми файлами. В системе реализованы метрики и лидерборд, которые помогают отслеживать активность пользователей и стимулируют более продуктивное взаимодействие с ботом, способствуя повышению эффективности работы агентства.

Решение реализовано с использованием фреймворка **LangChain** и схема графа выглядит следующим образом:
![Граф](./assets/graph.png)


## Структура проекта

Проект разделен на несколько ключевых директорий:

```plaintext
sber-reports-rag/
│
├── data/                      # Папка с данными
│   ├── interim/               # Промежуточные данные
│   │   ├── images/            # Изображения, извлеченные из pdf
│   │   ├── texts/             # Тексты с описаниями изображений
│   ├── raw/                   # Сырые данные (сам отчёт в pdf)
│   ├── vectorstore/           # Хранилище с векторами документов
│
├── notebooks/                 # Jupyter-ноутбуки с экспериментами
│
├── sber_reports_rag/          # Основной исходный код проекта
│   ├── backend/               # Логика работы бэкенда 
│   ├── data/                  # Логика предобработки данных
│   ├── utils/                 # Вспомогательные функции и промпты
│   ├── streamlit_app.py       # Реализация UI
│
├── assets/                    # Медиа-файлы для проекта
│
└── README.md                  # Описание проекта
```

## Подготовка данных и создание векторного хранилища

1. **Сбор документов**:
   Сначала необходимо исходный файлы pdf положить в `data`. 

2. **Создание текстов из pdf файла**:
   После этого, выполните следующую команду для создания документов из pdf файла:

   ```bash
   python -m sber_reports_rag/data/data_preparation.py
   ```

   Этот шаг разделит pdf файл на страницы и каждую из них преобразует в текст, описав изображения при помощи gpt4o-mini. Итоговые тексты сохранятся в папке `data/interim/texts/`. В настоящий момент они там уже лежат для удобства.

3. **Создание векторного хранилища**:
   После этого, выполните следующую команду для создания векторного хранилища из текстов:

   ```bash
   python -m sber_reports_rag/backend/rag.py
   ```

   Этот шаг создаст векторную базу и сохранит эмбеддинги документов в папке `data/vectorstore/`.

## Запуск приложения

Для запуска Streamlit приложения выполните следующие шаги:

1. Убедитесь, что все зависимости установлены:

   ```bash
   pip install -r requirements.txt
   ```

2. Запустите приложение Streamlit:

   ```bash
   streamlit run sber_reports_rag/streamlit_app.py
   ```

3. Перейдите в браузер и откройте локальный хост по адресу:

   ```plaintext
   http://localhost:8501
   ```

   Теперь вы сможете взаимодействовать с чат-ботом и задавать вопросы.

 # :computer: ## Пример использования

После запуска приложения вы сможете задать свой вопрос, и система сгенерирует ответ на основе информации, найденной в документах или в случае, если после 3х переформулировок запроса ничего подходящего не сгенерировалось, то найденной с использованием движка TavilySearch. Ниже приведены примеры взаимодействия:

1. Чат-бот верно отвечает на вопросы по pdf документу
   
   ![Первый пример](./assets/example1.png)

2. Чат-бот не галлюцинирует при ответах на вопросы, когда информации нет.
   ![Второй пример](./assets/example_hall.png)

3. Чат-бот использует движок TavilySearch для ответов на прочие вопросы
   ![Третий пример](./assets/example_tavily.png)

Также в проекте пока что просто печатаются в терминал логи, по которым можно понять, какая именно стадия сейчас обрабатывается, с какой попытки получен ответ на вопрос и т.д.
   ![Логирование пример](./assets/example_logs.png)

# :checkered_flag: ## Основные проблемы и решения

## :exploding_head: ### Обработка исходных PDF документов

Мультимодальный ретривер ColPali (https://huggingface.co/vidore/colpali-v1.3)
Основная сложность заключалась в том, что важные сведения были распределены между визуальными и текстовыми частями документа. К примеру, количественные показатели могли находиться в одном изображении, а их объяснения - либо в другом изображении, либо в тексте. Из-за такой фрагментированной организации информации было непросто корректно соединить и осмыслить все связанные данные. Изначально использовали библиотеку docling для обработки таких документов c пременением OCR: EasyOCR, Tesseract, Surya но это обработка затянулась на часы.
 

## :hugs: ### Принятое решение

мультимодальный ретривер, захватывающий текст и изображение в единый вектор.
Выбрали ColPali потому что:
а) в 20 раз быстрее библиотек docling+OCR (сейчас страница обрабатывается около 20сек)
б) является одним из лучших мультимодальных ретриверов. ссылка(https://huggingface.co/spaces/vidore/vidore-leaderboard)
в) не взяли топ-1 colbert потому что на нашем датасете (500 вопросов, 50/50 ручные и синтетические). Очевидно потому что colpali обучался на multilingual-датасете 

2. LLM Vikhr-2.5-VL-2b-Instruct, потому что:
а) Обучена на российском наборе данных
б) основана на QWEN c открытой лицензией до 100млн пользователей 

3. Инференс: V-LLM, потому что:
а) Быстрая генерация параллельных ответов
б) Легко масштабируется

Инференс: GPU 1x4080 16Gb


## made with ♥️ by AiRina for 
![header-logo c7e8f395](assets/12345.png)



